{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2feb9ec5",
      "metadata": {
        "id": "2feb9ec5",
        "outputId": "82637166-2f59-4440-ba6c-377965876fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preprocessing and feature extraction\n",
        "- Paper uses time-frequency patches that are extracted from the log-scaled mel-spectrogram as input into the model. (Details in â€œUnsupervised feature learning for urban sound classification\" paper)"
      ],
      "metadata": {
        "id": "qjDellFbAzZi"
      },
      "id": "qjDellFbAzZi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Reading in data using librosa"
      ],
      "metadata": {
        "id": "Xyr2yFagSJm8"
      },
      "id": "Xyr2yFagSJm8"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qEVPex7sAyl0"
      },
      "id": "qEVPex7sAyl0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Extracting log-scaled mel spectrogram using Essentia"
      ],
      "metadata": {
        "id": "j2SfE9jHSRna"
      },
      "id": "j2SfE9jHSRna"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u3HTSahPAy4D"
      },
      "id": "u3HTSahPAy4D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Getting the TF patches"
      ],
      "metadata": {
        "id": "vx4foztkSU1f"
      },
      "id": "vx4foztkSU1f"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKxfDBqEAzAE"
      },
      "id": "zKxfDBqEAzAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Baseline model architecture\n",
        "- 3 Convolutional Layers\n",
        "- 2 Dense Linear Layers"
      ],
      "metadata": {
        "id": "kKEDBK-lAwYW"
      },
      "id": "kKEDBK-lAwYW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Code heavily references the paper on Environmental Sound Classification on Microcontrollers using Convolutional Neural Networks\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.regularizers import l2"
      ],
      "metadata": {
        "id": "VQd4ph7ubTVg"
      },
      "id": "VQd4ph7ubTVg",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check for how many channels we have\n",
        "\n",
        "frames=128 # Number of time frames we have\n",
        "bands=128 # Number of Mel Bands\n",
        "channels=1# Number of input channels, determines what kind of convolution we use\n",
        "num_labels=10 # Number of audio target labels\n",
        "conv_size=(5,5) # Size of each filter/kernel\n",
        "conv_block='conv'\n",
        "downsample_size=(4,2) # Stride size\n",
        "fully_connected=64 # Dense layer number of neurons\n",
        "n_stages=None\n",
        "n_blocks_per_stage=None\n",
        "filters=24\n",
        "kernels_growth=2 # After each convolutional layer, the paper includes growth of filter\n",
        "dropout=0.5\n",
        "use_strides=False\n",
        "\n",
        "Conv2 = SeparableConv2D if conv_block == 'depthwise_separable' else Convolution2D\n",
        "\n",
        "\n",
        "kernel = conv_size # Size of each filter/kernel\n",
        "if use_strides: # How much each filter moves\n",
        "  strides = downsample_size\n",
        "  pool = (1, 1)\n",
        "else:\n",
        "  strides = (1, 1)\n",
        "  pool = downsample_size\n",
        "\n",
        "# First Block assumes 2D Convolution i.e. input has one channel\n",
        "\n",
        "block1 = [\n",
        "  Convolution2D(filters, kernel, padding='same', strides=strides,\n",
        "  input_shape=(bands, frames, channels)),\n",
        "  BatchNormalization(),\n",
        "  MaxPooling2D(pool_size=pool),\n",
        "  Activation('relu'),\n",
        "  ]\n",
        "\n",
        "\n",
        "block2 = [\n",
        "  Conv2(filters*kernels_growth, kernel, padding='same', strides=strides),\n",
        "  BatchNormalization(),\n",
        "           MaxPooling2D(pool_size=pool),\n",
        "  Activation('relu'),\n",
        "]\n",
        "\n",
        "block3 = [\n",
        "  Conv2(filters*kernels_growth, kernel, padding='valid', strides=strides),\n",
        "  BatchNormalization(),\n",
        "  Activation('relu'),\n",
        "]\n",
        "\n",
        "backend = [\n",
        "  Flatten(),\n",
        "  Dropout(dropout),\n",
        "  Dense(fully_connected, kernel_regularizer=l2(0.001)),\n",
        "  Activation('relu'),\n",
        "  Dropout(dropout),\n",
        "  Dense(num_labels, kernel_regularizer=l2(0.001)),\n",
        "  Activation('softmax'),\n",
        "]\n",
        "layers = block1 + block2 + block3 + backend\n",
        "model = Sequential(layers)"
      ],
      "metadata": {
        "id": "GyokWruJ6GZ5"
      },
      "id": "GyokWruJ6GZ5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "Mcf2ChrVpfbg"
      },
      "id": "Mcf2ChrVpfbg"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hMbWc5b-per9"
      },
      "id": "hMbWc5b-per9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "-fmsJn7XphSt"
      },
      "id": "-fmsJn7XphSt"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-9X62ZNpifT"
      },
      "id": "Q-9X62ZNpifT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}